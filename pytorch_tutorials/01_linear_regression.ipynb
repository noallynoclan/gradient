{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': tensor([[ 0.0497, -0.0138,  0.0648],\n",
      "        [ 0.1523, -0.0234, -0.0234]], requires_grad=True),\n",
      " 'b': tensor([0.1579, 0.0767], requires_grad=True)}\n",
      "tensor(7063.5811, grad_fn=<DivBackward0>)\n",
      "'dW'\n",
      "tensor([[-5663.6494, -6960.6177, -4136.5859],\n",
      "        [-6730.3169, -8101.4106, -4872.5522]])\n",
      "tensor(4947.7710, grad_fn=<DivBackward0>)\n",
      "'dW'\n",
      "tensor([[-4569.6934, -5779.8867, -3409.1182],\n",
      "        [-5444.3818, -6714.4644, -4017.7886]])\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "], dtype='float32')\n",
    "targets = np.array([\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]\n",
    "], dtype='float32')\n",
    "\n",
    "def ver1():\n",
    "    np.random.seed(42)\n",
    "    x = torch.from_numpy(inputs) # (None, 3)\n",
    "    y = torch.from_numpy(targets) # (None, 2)\n",
    "    \n",
    "#     w = torch.randn(2, 3, requires_grad=True) # num_outputs, num_inputs\n",
    "#     b = torch.randn(2, requires_grad=True)\n",
    "    \n",
    "    w = np.random.normal(scale=0.1, size=(2, 3))\n",
    "    w = torch.tensor(w, dtype=torch.float32, requires_grad=True)\n",
    "    b = np.random.normal(scale=0.1, size=(2))\n",
    "    b = torch.tensor(b, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    pprint({'W': w, 'b': b})\n",
    "    \n",
    "    def model(x):\n",
    "        return x @ w.t() + b # (None, 2)\n",
    "\n",
    "    def mse(y_pred, y_true):\n",
    "        diff = y_pred - y_true\n",
    "        return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "    for i in range(2):\n",
    "        y_pred = model(x)\n",
    "        # print(y_pred)\n",
    "        loss = mse(y, model(x)) \n",
    "        print(loss)\n",
    "#         if i % 1000 == 0:\n",
    "#             print(i, loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "        pprint('dW')\n",
    "        print(w.grad)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * 1e-5\n",
    "            b -= b.grad * 1e-5\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "    \n",
    "            \n",
    "ver1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 91.,  88.,  64.]]), tensor([[ 22.,  37.],\n",
      "        [103., 119.],\n",
      "        [ 22.,  37.],\n",
      "        [ 81., 101.]])]\n",
      "tensor(9130.4795, grad_fn=<MseLossBackward>)\n",
      "0 6213.703125\n",
      "1000 1.6922653913497925\n",
      "2000 0.4158349931240082\n",
      "3000 0.70238196849823\n",
      "4000 0.5885873436927795\n",
      "5000 0.528420627117157\n",
      "6000 0.6098266243934631\n",
      "7000 0.4385601580142975\n",
      "8000 0.5441039204597473\n",
      "9000 0.6226803660392761\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "\n",
    "def ver2():\n",
    "    x = torch.from_numpy(inputs) # (None, 3)\n",
    "    y = torch.from_numpy(targets) # (None, 2)\n",
    "    train_ds = TensorDataset(x, y)\n",
    "    # print(train_ds[0])\n",
    "    train_dl = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "    for i in train_dl:\n",
    "        print(i)\n",
    "        break\n",
    "        \n",
    "    model = nn.Linear(in_features=3, out_features=2)\n",
    "    # print(model.weight, model.bias)\n",
    "    loss_fn = nn.functional.mse_loss\n",
    "    # opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    print(loss_fn(model(x), y))\n",
    "    \n",
    "    def fit(num_epochs, model, loss_fn, opt):\n",
    "        for epoch in range(num_epochs):\n",
    "            for xb, yb in train_dl:\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                loss.backward() # compute gradients\n",
    "                opt.step() # update parameters using gradients\n",
    "                opt.zero_grad()\n",
    "            if epoch % 1000 == 0:\n",
    "                print(epoch, loss.item())\n",
    "                \n",
    "    fit(10000, model, loss_fn, opt)\n",
    "                \n",
    "ver2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3925, -0.4187, -0.3082],\n",
      "        [ 0.5287, -0.1948, -0.2047]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.5586, -0.3306], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(in_features=3, out_features=2)\n",
    "print(model.weight, model.bias)\n",
    "loss_fn = nn.functional.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
