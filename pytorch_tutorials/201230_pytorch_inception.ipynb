{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install torchsummary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INCEPTION_201230'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "PROJECT = 'INCEPTION_{}'.format(datetime.now().strftime('%y%m%d'))\n",
    "PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.0%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:439: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data_loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(data_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x).argmax(1)\n",
    "            num_correct += (y == y_pred).sum()\n",
    "            num_samples += y.size(0)\n",
    "    acc = num_correct / num_samples\n",
    "    return acc\n",
    "\n",
    "def train(run_name, model, data_loader, num_epochs=2, learning_rate=1e-3):\n",
    "    name = '{}_{}'.format(run_name, datetime.now().strftime('%H%M%S'))\n",
    "    wandb.init(project=PROJECT, name=name)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time()\n",
    "        for batch_idx, (x, y) in enumerate(data_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            scores = model(x)\n",
    "            loss = loss_fun(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({'loss': loss})\n",
    "        print(f'epoch {epoch}, {time() - start_time:.1f}s: {accuracy(model, data_loader):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$O=\\frac{I+2P-K}{S}+1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "              ReLU-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              ReLU-5           [-1, 16, 10, 10]               0\n",
      "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Conv2d-7            [-1, 120, 1, 1]          48,120\n",
      "              ReLU-8            [-1, 120, 1, 1]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             ReLU-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.35\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:sji7eib3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1695<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf3006c14a44fdc91152569f5da610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1215, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1366, in _on_finish\n",
      "    ret = self._wait_for_finish()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1329, in _wait_for_finish\n",
      "    self._on_finish_progress(pusher_stats, done)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1318, in _on_finish_progress\n",
      "    self._pusher_print_status(progress, done=done)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1294, in _pusher_print_status\n",
      "    self._jupyter_progress.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/ipython.py\", line 79, in close\n",
      "    self._widget.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipywidgets/widgets/widget.py\", line 469, in close\n",
      "    self.comm.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/comm/comm.py\", line 116, in close\n",
      "    self.kernel.comm_manager.unregister_comm(self)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/comm/manager.py\", line 56, in unregister_comm\n",
      "    comm = self.comms.pop(comm.comm_id)\n",
      "KeyError: 'eaf3006c14a44fdc91152569f5da610e'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:sji7eib3). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">LeNet_150055</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230/runs/2u4r0kv5\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230/runs/2u4r0kv5</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20201230_150055-2u4r0kv5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 10.9s: 95.5%\n",
      "epoch 1, 10.5s: 97.0%\n",
      "test: 97.1%\n"
     ]
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=(5, 5), stride=(1, 1), padding=(0, 0))\n",
    "        self.linear1 = nn.Linear(120, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.conv1(x)) \n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x)) \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "summary(model, (1, 28, 28))\n",
    "train('LeNet', model, train_loader)\n",
    "print(f'test: {accuracy(model, test_loader):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 28, 28]              80\n",
      "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
      "              ReLU-3            [-1, 8, 28, 28]               0\n",
      "            Conv2d-4            [-1, 8, 28, 28]             584\n",
      "       BatchNorm2d-5            [-1, 8, 28, 28]              16\n",
      "              ReLU-6            [-1, 8, 28, 28]               0\n",
      "         MaxPool2d-7            [-1, 8, 14, 14]               0\n",
      "            Conv2d-8           [-1, 16, 14, 14]           1,168\n",
      "       BatchNorm2d-9           [-1, 16, 14, 14]              32\n",
      "             ReLU-10           [-1, 16, 14, 14]               0\n",
      "           Conv2d-11           [-1, 16, 14, 14]           2,320\n",
      "      BatchNorm2d-12           [-1, 16, 14, 14]              32\n",
      "             ReLU-13           [-1, 16, 14, 14]               0\n",
      "        MaxPool2d-14             [-1, 16, 7, 7]               0\n",
      "           Linear-15                   [-1, 64]          50,240\n",
      "             ReLU-16                   [-1, 64]               0\n",
      "          Dropout-17                   [-1, 64]               0\n",
      "           Linear-18                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 55,138\n",
      "Trainable params: 55,138\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 0.66\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">VGG_145912</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230/runs/sji7eib3\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230/runs/sji7eib3</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20201230_145912-sji7eib3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 13.4s: 98.3%\n",
      "epoch 1, 13.3s: 98.7%\n",
      "test: 98.7%\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, architecture, in_channels=3, in_size=(224, 224)):\n",
    "        super(VGG, self).__init__()\n",
    "        self.cnv = self.create_conv_layers(in_channels, architecture[0])\n",
    "        out_size = torch.tensor(in_size) // 2 ** architecture[0].count('M')\n",
    "        self.fcs = self.create_fcs_layers(architecture[0][-2] * out_size.prod(), architecture[1])\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnv(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "        \n",
    "    def create_conv_layers(self, in_channels, architecture):\n",
    "        layers = []\n",
    "        for out in architecture:\n",
    "            if type(out) == int:\n",
    "                layers += [\n",
    "                    nn.Conv2d(in_channels, out, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                    nn.BatchNorm2d(out),\n",
    "                    nn.ReLU()\n",
    "                ]\n",
    "                in_channels = out\n",
    "            elif out == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def create_fcs_layers(self, in_channels, architecture):\n",
    "        layers = []\n",
    "        for out in architecture[:-1]:\n",
    "            layers += [\n",
    "                nn.Linear(in_channels, out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.5)\n",
    "            ]\n",
    "            in_channels = out\n",
    "        layers += [nn.Linear(in_channels, architecture[-1])]\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "tiny = [\n",
    "    [8, 8, 'M', 16, 16, 'M'],\n",
    "    [64, 10]\n",
    "]\n",
    "\n",
    "model = VGG(tiny, in_channels=1, in_size=(28, 28))\n",
    "summary(model, (1, 28, 28))\n",
    "train('VGG', model, train_loader)\n",
    "print(f'test: {accuracy(model, test_loader):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/700/1*U_McJnp7Fnif-lw9iIC5Bw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10000])\n"
     ]
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\n",
    "    \n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1_pool):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.branch1 = ConvBlock(in_channels, out_1x1, kernel_size=1)\n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_channels, red_3x3, kernel_size=1),\n",
    "            ConvBlock(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_channels, red_5x5, kernel_size=1),\n",
    "            ConvBlock(red_5x5, out_5x5, kernel_size=5, padding=2),\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_channels, out_1x1_pool, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
    "    \n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10000):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = ConvBlock(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(1024, num_classes)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 3, 224, 224).to(device)\n",
    "    model = GoogLeNet()\n",
    "    print(model(x).shape)\n",
    "    # summary(model, (3, 224, 224))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         ConvBlock-4           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-5             [-1, 64, 7, 7]               0\n",
      "            Conv2d-6            [-1, 192, 7, 7]         110,784\n",
      "       BatchNorm2d-7            [-1, 192, 7, 7]             384\n",
      "              ReLU-8            [-1, 192, 7, 7]               0\n",
      "         ConvBlock-9            [-1, 192, 7, 7]               0\n",
      "        MaxPool2d-10            [-1, 192, 4, 4]               0\n",
      "           Conv2d-11             [-1, 64, 4, 4]          12,352\n",
      "      BatchNorm2d-12             [-1, 64, 4, 4]             128\n",
      "             ReLU-13             [-1, 64, 4, 4]               0\n",
      "        ConvBlock-14             [-1, 64, 4, 4]               0\n",
      "           Conv2d-15             [-1, 96, 4, 4]          18,528\n",
      "      BatchNorm2d-16             [-1, 96, 4, 4]             192\n",
      "             ReLU-17             [-1, 96, 4, 4]               0\n",
      "        ConvBlock-18             [-1, 96, 4, 4]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]         110,720\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "        ConvBlock-22            [-1, 128, 4, 4]               0\n",
      "           Conv2d-23             [-1, 16, 4, 4]           3,088\n",
      "      BatchNorm2d-24             [-1, 16, 4, 4]              32\n",
      "             ReLU-25             [-1, 16, 4, 4]               0\n",
      "        ConvBlock-26             [-1, 16, 4, 4]               0\n",
      "           Conv2d-27             [-1, 32, 4, 4]          12,832\n",
      "      BatchNorm2d-28             [-1, 32, 4, 4]              64\n",
      "             ReLU-29             [-1, 32, 4, 4]               0\n",
      "        ConvBlock-30             [-1, 32, 4, 4]               0\n",
      "        MaxPool2d-31            [-1, 192, 4, 4]               0\n",
      "           Conv2d-32             [-1, 32, 4, 4]           6,176\n",
      "      BatchNorm2d-33             [-1, 32, 4, 4]              64\n",
      "             ReLU-34             [-1, 32, 4, 4]               0\n",
      "        ConvBlock-35             [-1, 32, 4, 4]               0\n",
      "   InceptionBlock-36            [-1, 256, 4, 4]               0\n",
      "           Conv2d-37            [-1, 128, 4, 4]          32,896\n",
      "      BatchNorm2d-38            [-1, 128, 4, 4]             256\n",
      "             ReLU-39            [-1, 128, 4, 4]               0\n",
      "        ConvBlock-40            [-1, 128, 4, 4]               0\n",
      "           Conv2d-41            [-1, 128, 4, 4]          32,896\n",
      "      BatchNorm2d-42            [-1, 128, 4, 4]             256\n",
      "             ReLU-43            [-1, 128, 4, 4]               0\n",
      "        ConvBlock-44            [-1, 128, 4, 4]               0\n",
      "           Conv2d-45            [-1, 192, 4, 4]         221,376\n",
      "      BatchNorm2d-46            [-1, 192, 4, 4]             384\n",
      "             ReLU-47            [-1, 192, 4, 4]               0\n",
      "        ConvBlock-48            [-1, 192, 4, 4]               0\n",
      "           Conv2d-49             [-1, 32, 4, 4]           8,224\n",
      "      BatchNorm2d-50             [-1, 32, 4, 4]              64\n",
      "             ReLU-51             [-1, 32, 4, 4]               0\n",
      "        ConvBlock-52             [-1, 32, 4, 4]               0\n",
      "           Conv2d-53             [-1, 96, 4, 4]          76,896\n",
      "      BatchNorm2d-54             [-1, 96, 4, 4]             192\n",
      "             ReLU-55             [-1, 96, 4, 4]               0\n",
      "        ConvBlock-56             [-1, 96, 4, 4]               0\n",
      "        MaxPool2d-57            [-1, 256, 4, 4]               0\n",
      "           Conv2d-58             [-1, 64, 4, 4]          16,448\n",
      "      BatchNorm2d-59             [-1, 64, 4, 4]             128\n",
      "             ReLU-60             [-1, 64, 4, 4]               0\n",
      "        ConvBlock-61             [-1, 64, 4, 4]               0\n",
      "   InceptionBlock-62            [-1, 480, 4, 4]               0\n",
      "        MaxPool2d-63            [-1, 480, 2, 2]               0\n",
      "           Conv2d-64            [-1, 192, 2, 2]          92,352\n",
      "      BatchNorm2d-65            [-1, 192, 2, 2]             384\n",
      "             ReLU-66            [-1, 192, 2, 2]               0\n",
      "        ConvBlock-67            [-1, 192, 2, 2]               0\n",
      "           Conv2d-68             [-1, 96, 2, 2]          46,176\n",
      "      BatchNorm2d-69             [-1, 96, 2, 2]             192\n",
      "             ReLU-70             [-1, 96, 2, 2]               0\n",
      "        ConvBlock-71             [-1, 96, 2, 2]               0\n",
      "           Conv2d-72            [-1, 208, 2, 2]         179,920\n",
      "      BatchNorm2d-73            [-1, 208, 2, 2]             416\n",
      "             ReLU-74            [-1, 208, 2, 2]               0\n",
      "        ConvBlock-75            [-1, 208, 2, 2]               0\n",
      "           Conv2d-76             [-1, 16, 2, 2]           7,696\n",
      "      BatchNorm2d-77             [-1, 16, 2, 2]              32\n",
      "             ReLU-78             [-1, 16, 2, 2]               0\n",
      "        ConvBlock-79             [-1, 16, 2, 2]               0\n",
      "           Conv2d-80             [-1, 48, 2, 2]          19,248\n",
      "      BatchNorm2d-81             [-1, 48, 2, 2]              96\n",
      "             ReLU-82             [-1, 48, 2, 2]               0\n",
      "        ConvBlock-83             [-1, 48, 2, 2]               0\n",
      "        MaxPool2d-84            [-1, 480, 2, 2]               0\n",
      "           Conv2d-85             [-1, 64, 2, 2]          30,784\n",
      "      BatchNorm2d-86             [-1, 64, 2, 2]             128\n",
      "             ReLU-87             [-1, 64, 2, 2]               0\n",
      "        ConvBlock-88             [-1, 64, 2, 2]               0\n",
      "   InceptionBlock-89            [-1, 512, 2, 2]               0\n",
      "           Conv2d-90            [-1, 160, 2, 2]          82,080\n",
      "      BatchNorm2d-91            [-1, 160, 2, 2]             320\n",
      "             ReLU-92            [-1, 160, 2, 2]               0\n",
      "        ConvBlock-93            [-1, 160, 2, 2]               0\n",
      "           Conv2d-94            [-1, 112, 2, 2]          57,456\n",
      "      BatchNorm2d-95            [-1, 112, 2, 2]             224\n",
      "             ReLU-96            [-1, 112, 2, 2]               0\n",
      "        ConvBlock-97            [-1, 112, 2, 2]               0\n",
      "           Conv2d-98            [-1, 224, 2, 2]         226,016\n",
      "      BatchNorm2d-99            [-1, 224, 2, 2]             448\n",
      "            ReLU-100            [-1, 224, 2, 2]               0\n",
      "       ConvBlock-101            [-1, 224, 2, 2]               0\n",
      "          Conv2d-102             [-1, 24, 2, 2]          12,312\n",
      "     BatchNorm2d-103             [-1, 24, 2, 2]              48\n",
      "            ReLU-104             [-1, 24, 2, 2]               0\n",
      "       ConvBlock-105             [-1, 24, 2, 2]               0\n",
      "          Conv2d-106             [-1, 64, 2, 2]          38,464\n",
      "     BatchNorm2d-107             [-1, 64, 2, 2]             128\n",
      "            ReLU-108             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-109             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-110            [-1, 512, 2, 2]               0\n",
      "          Conv2d-111             [-1, 64, 2, 2]          32,832\n",
      "     BatchNorm2d-112             [-1, 64, 2, 2]             128\n",
      "            ReLU-113             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-114             [-1, 64, 2, 2]               0\n",
      "  InceptionBlock-115            [-1, 512, 2, 2]               0\n",
      "          Conv2d-116            [-1, 128, 2, 2]          65,664\n",
      "     BatchNorm2d-117            [-1, 128, 2, 2]             256\n",
      "            ReLU-118            [-1, 128, 2, 2]               0\n",
      "       ConvBlock-119            [-1, 128, 2, 2]               0\n",
      "          Conv2d-120            [-1, 128, 2, 2]          65,664\n",
      "     BatchNorm2d-121            [-1, 128, 2, 2]             256\n",
      "            ReLU-122            [-1, 128, 2, 2]               0\n",
      "       ConvBlock-123            [-1, 128, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         295,168\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "       ConvBlock-127            [-1, 256, 2, 2]               0\n",
      "          Conv2d-128             [-1, 24, 2, 2]          12,312\n",
      "     BatchNorm2d-129             [-1, 24, 2, 2]              48\n",
      "            ReLU-130             [-1, 24, 2, 2]               0\n",
      "       ConvBlock-131             [-1, 24, 2, 2]               0\n",
      "          Conv2d-132             [-1, 64, 2, 2]          38,464\n",
      "     BatchNorm2d-133             [-1, 64, 2, 2]             128\n",
      "            ReLU-134             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-135             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-136            [-1, 512, 2, 2]               0\n",
      "          Conv2d-137             [-1, 64, 2, 2]          32,832\n",
      "     BatchNorm2d-138             [-1, 64, 2, 2]             128\n",
      "            ReLU-139             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-140             [-1, 64, 2, 2]               0\n",
      "  InceptionBlock-141            [-1, 512, 2, 2]               0\n",
      "          Conv2d-142            [-1, 112, 2, 2]          57,456\n",
      "     BatchNorm2d-143            [-1, 112, 2, 2]             224\n",
      "            ReLU-144            [-1, 112, 2, 2]               0\n",
      "       ConvBlock-145            [-1, 112, 2, 2]               0\n",
      "          Conv2d-146            [-1, 144, 2, 2]          73,872\n",
      "     BatchNorm2d-147            [-1, 144, 2, 2]             288\n",
      "            ReLU-148            [-1, 144, 2, 2]               0\n",
      "       ConvBlock-149            [-1, 144, 2, 2]               0\n",
      "          Conv2d-150            [-1, 288, 2, 2]         373,536\n",
      "     BatchNorm2d-151            [-1, 288, 2, 2]             576\n",
      "            ReLU-152            [-1, 288, 2, 2]               0\n",
      "       ConvBlock-153            [-1, 288, 2, 2]               0\n",
      "          Conv2d-154             [-1, 32, 2, 2]          16,416\n",
      "     BatchNorm2d-155             [-1, 32, 2, 2]              64\n",
      "            ReLU-156             [-1, 32, 2, 2]               0\n",
      "       ConvBlock-157             [-1, 32, 2, 2]               0\n",
      "          Conv2d-158             [-1, 64, 2, 2]          51,264\n",
      "     BatchNorm2d-159             [-1, 64, 2, 2]             128\n",
      "            ReLU-160             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-161             [-1, 64, 2, 2]               0\n",
      "       MaxPool2d-162            [-1, 512, 2, 2]               0\n",
      "          Conv2d-163             [-1, 64, 2, 2]          32,832\n",
      "     BatchNorm2d-164             [-1, 64, 2, 2]             128\n",
      "            ReLU-165             [-1, 64, 2, 2]               0\n",
      "       ConvBlock-166             [-1, 64, 2, 2]               0\n",
      "  InceptionBlock-167            [-1, 528, 2, 2]               0\n",
      "          Conv2d-168            [-1, 256, 2, 2]         135,424\n",
      "     BatchNorm2d-169            [-1, 256, 2, 2]             512\n",
      "            ReLU-170            [-1, 256, 2, 2]               0\n",
      "       ConvBlock-171            [-1, 256, 2, 2]               0\n",
      "          Conv2d-172            [-1, 160, 2, 2]          84,640\n",
      "     BatchNorm2d-173            [-1, 160, 2, 2]             320\n",
      "            ReLU-174            [-1, 160, 2, 2]               0\n",
      "       ConvBlock-175            [-1, 160, 2, 2]               0\n",
      "          Conv2d-176            [-1, 320, 2, 2]         461,120\n",
      "     BatchNorm2d-177            [-1, 320, 2, 2]             640\n",
      "            ReLU-178            [-1, 320, 2, 2]               0\n",
      "       ConvBlock-179            [-1, 320, 2, 2]               0\n",
      "          Conv2d-180             [-1, 32, 2, 2]          16,928\n",
      "     BatchNorm2d-181             [-1, 32, 2, 2]              64\n",
      "            ReLU-182             [-1, 32, 2, 2]               0\n",
      "       ConvBlock-183             [-1, 32, 2, 2]               0\n",
      "          Conv2d-184            [-1, 128, 2, 2]         102,528\n",
      "     BatchNorm2d-185            [-1, 128, 2, 2]             256\n",
      "            ReLU-186            [-1, 128, 2, 2]               0\n",
      "       ConvBlock-187            [-1, 128, 2, 2]               0\n",
      "       MaxPool2d-188            [-1, 528, 2, 2]               0\n",
      "          Conv2d-189            [-1, 128, 2, 2]          67,712\n",
      "     BatchNorm2d-190            [-1, 128, 2, 2]             256\n",
      "            ReLU-191            [-1, 128, 2, 2]               0\n",
      "       ConvBlock-192            [-1, 128, 2, 2]               0\n",
      "  InceptionBlock-193            [-1, 832, 2, 2]               0\n",
      "       MaxPool2d-194            [-1, 832, 1, 1]               0\n",
      "          Conv2d-195            [-1, 256, 1, 1]         213,248\n",
      "     BatchNorm2d-196            [-1, 256, 1, 1]             512\n",
      "            ReLU-197            [-1, 256, 1, 1]               0\n",
      "       ConvBlock-198            [-1, 256, 1, 1]               0\n",
      "          Conv2d-199            [-1, 160, 1, 1]         133,280\n",
      "     BatchNorm2d-200            [-1, 160, 1, 1]             320\n",
      "            ReLU-201            [-1, 160, 1, 1]               0\n",
      "       ConvBlock-202            [-1, 160, 1, 1]               0\n",
      "          Conv2d-203            [-1, 320, 1, 1]         461,120\n",
      "     BatchNorm2d-204            [-1, 320, 1, 1]             640\n",
      "            ReLU-205            [-1, 320, 1, 1]               0\n",
      "       ConvBlock-206            [-1, 320, 1, 1]               0\n",
      "          Conv2d-207             [-1, 32, 1, 1]          26,656\n",
      "     BatchNorm2d-208             [-1, 32, 1, 1]              64\n",
      "            ReLU-209             [-1, 32, 1, 1]               0\n",
      "       ConvBlock-210             [-1, 32, 1, 1]               0\n",
      "          Conv2d-211            [-1, 128, 1, 1]         102,528\n",
      "     BatchNorm2d-212            [-1, 128, 1, 1]             256\n",
      "            ReLU-213            [-1, 128, 1, 1]               0\n",
      "       ConvBlock-214            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-215            [-1, 832, 1, 1]               0\n",
      "          Conv2d-216            [-1, 128, 1, 1]         106,624\n",
      "     BatchNorm2d-217            [-1, 128, 1, 1]             256\n",
      "            ReLU-218            [-1, 128, 1, 1]               0\n",
      "       ConvBlock-219            [-1, 128, 1, 1]               0\n",
      "  InceptionBlock-220            [-1, 832, 1, 1]               0\n",
      "          Conv2d-221            [-1, 384, 1, 1]         319,872\n",
      "     BatchNorm2d-222            [-1, 384, 1, 1]             768\n",
      "            ReLU-223            [-1, 384, 1, 1]               0\n",
      "       ConvBlock-224            [-1, 384, 1, 1]               0\n",
      "          Conv2d-225            [-1, 192, 1, 1]         159,936\n",
      "     BatchNorm2d-226            [-1, 192, 1, 1]             384\n",
      "            ReLU-227            [-1, 192, 1, 1]               0\n",
      "       ConvBlock-228            [-1, 192, 1, 1]               0\n",
      "          Conv2d-229            [-1, 384, 1, 1]         663,936\n",
      "     BatchNorm2d-230            [-1, 384, 1, 1]             768\n",
      "            ReLU-231            [-1, 384, 1, 1]               0\n",
      "       ConvBlock-232            [-1, 384, 1, 1]               0\n",
      "          Conv2d-233             [-1, 48, 1, 1]          39,984\n",
      "     BatchNorm2d-234             [-1, 48, 1, 1]              96\n",
      "            ReLU-235             [-1, 48, 1, 1]               0\n",
      "       ConvBlock-236             [-1, 48, 1, 1]               0\n",
      "          Conv2d-237            [-1, 128, 1, 1]         153,728\n",
      "     BatchNorm2d-238            [-1, 128, 1, 1]             256\n",
      "            ReLU-239            [-1, 128, 1, 1]               0\n",
      "       ConvBlock-240            [-1, 128, 1, 1]               0\n",
      "       MaxPool2d-241            [-1, 832, 1, 1]               0\n",
      "          Conv2d-242            [-1, 128, 1, 1]         106,624\n",
      "     BatchNorm2d-243            [-1, 128, 1, 1]             256\n",
      "            ReLU-244            [-1, 128, 1, 1]               0\n",
      "       ConvBlock-245            [-1, 128, 1, 1]               0\n",
      "  InceptionBlock-246           [-1, 1024, 1, 1]               0\n",
      "         Dropout-247                 [-1, 1024]               0\n",
      "          Linear-248                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 5,987,802\n",
      "Trainable params: 5,987,802\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.09\n",
      "Params size (MB): 22.84\n",
      "Estimated Total Size (MB): 24.94\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2u4r0kv5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 1834<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdce034ccb4848a19946501a0088aeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1215, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1366, in _on_finish\n",
      "    ret = self._wait_for_finish()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1329, in _wait_for_finish\n",
      "    self._on_finish_progress(pusher_stats, done)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1318, in _on_finish_progress\n",
      "    self._pusher_print_status(progress, done=done)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\", line 1294, in _pusher_print_status\n",
      "    self._jupyter_progress.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/ipython.py\", line 79, in close\n",
      "    self._widget.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipywidgets/widgets/widget.py\", line 469, in close\n",
      "    self.comm.close()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/comm/comm.py\", line 116, in close\n",
      "    self.kernel.comm_manager.unregister_comm(self)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/comm/manager.py\", line 56, in unregister_comm\n",
      "    comm = self.comms.pop(comm.comm_id)\n",
      "KeyError: 'fdce034ccb4848a19946501a0088aeb7'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2u4r0kv5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">TinyInception_154812</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_201230/runs/1nc7avfx\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_201230/runs/1nc7avfx</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20201230_154812-1nc7avfx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 69.4s: 97.4%\n",
      "epoch 1, 69.7s: 97.6%\n",
      "test: 97.6%\n"
     ]
    }
   ],
   "source": [
    "class TinyInception(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(TinyInception, self).__init__()\n",
    "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = ConvBlock(64, 192, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3a = InceptionBlock(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = InceptionBlock(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception4a = InceptionBlock(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = InceptionBlock(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = InceptionBlock(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = InceptionBlock(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = InceptionBlock(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception5a = InceptionBlock(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = InceptionBlock(832, 384, 192, 384, 48, 128, 128)\n",
    "        # self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(1024, num_classes)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        # x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# x = torch.randn(3, 1, 28, 28).to(device)\n",
    "# model = TinyInception()\n",
    "# print(model(x).shape)\n",
    "\n",
    "model =  TinyInception()\n",
    "summary(model, (1, 28, 28))\n",
    "train('TinyInception', model, train_loader)\n",
    "print(f'test: {accuracy(model, test_loader):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
