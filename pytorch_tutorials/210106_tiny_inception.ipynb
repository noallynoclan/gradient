{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! pip install torchsummary -q\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'INCEPTION_210106'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "PROJECT = 'INCEPTION_{}'.format(datetime.now().strftime('%y%m%d'))\n",
    "PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:439: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, data_loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, y) in enumerate(data_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x).argmax(1)\n",
    "            num_correct += (y == y_pred).sum()\n",
    "            num_samples += y.size(0)\n",
    "    acc = num_correct / num_samples\n",
    "    return acc\n",
    "\n",
    "def train(run_name, model, data_loader, num_epochs=30, learning_rate=1e-3):\n",
    "    name = '{}_{}'.format(run_name, datetime.now().strftime('%H%M%S'))\n",
    "    wandb.init(project=PROJECT, name=name)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, verbose=True)\n",
    "    loss_fun = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time()\n",
    "        losses = []\n",
    "        for batch_idx, (x, y) in enumerate(data_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            scores = model(x)\n",
    "            loss = loss_fun(scores, y)\n",
    "            losses.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({'loss': loss})\n",
    "        mean_loss = sum(losses) / len(losses)    \n",
    "        scheduler.step(mean_loss)\n",
    "        \n",
    "        print(f'epoch {epoch}, {time() - start_time:.1f}s: {accuracy(model, data_loader):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3askhrcw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3391<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9b0233d03e4ac08c043b8610b3ef6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20210106_145007-3askhrcw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20210106_145007-3askhrcw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>0.01602</td></tr><tr><td>_step</td><td>1875</td></tr><tr><td>_runtime</td><td>82</td></tr><tr><td>_timestamp</td><td>1609944692</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>loss</td><td>█▃▂▂▂▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">TinyInception_145007</strong>: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_210106/runs/3askhrcw\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_210106/runs/3askhrcw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3askhrcw). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.12<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">TinyInception_145212</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_210106\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_210106</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wegoplaces/INCEPTION_210106/runs/3n9yzp7l\" target=\"_blank\">https://wandb.ai/wegoplaces/INCEPTION_210106/runs/3n9yzp7l</a><br/>\n",
       "                Run data is saved locally in <code>/notebooks/gradient_nbs/pytorch_tutorials/wandb/run-20210106_145212-3n9yzp7l</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 35.6s: 98.6%\n",
      "epoch 1, 35.5s: 99.0%\n",
      "epoch 2, 35.6s: 98.9%\n",
      "epoch 3, 35.4s: 99.5%\n",
      "epoch 4, 35.2s: 99.6%\n",
      "epoch 5, 35.2s: 99.4%\n",
      "epoch 6, 36.4s: 99.5%\n",
      "epoch 7, 35.5s: 99.5%\n",
      "epoch 8, 35.1s: 99.4%\n",
      "epoch 9, 36.4s: 99.7%\n",
      "epoch 10, 35.9s: 99.8%\n",
      "epoch 11, 36.4s: 99.7%\n",
      "epoch 12, 36.5s: 99.4%\n",
      "epoch 13, 36.0s: 99.7%\n",
      "epoch 14, 36.3s: 99.7%\n",
      "epoch 15, 35.1s: 99.7%\n",
      "epoch 16, 35.5s: 99.8%\n",
      "epoch 17, 35.9s: 99.8%\n",
      "epoch 18, 34.8s: 99.8%\n",
      "epoch 19, 35.6s: 99.8%\n",
      "epoch 20, 35.8s: 99.8%\n",
      "epoch 21, 35.2s: 99.9%\n",
      "epoch 22, 35.4s: 99.9%\n",
      "epoch 23, 35.5s: 99.9%\n",
      "epoch 24, 35.7s: 99.9%\n",
      "epoch 25, 34.8s: 99.9%\n",
      "epoch 26, 35.5s: 99.9%\n",
      "epoch 27, 35.6s: 99.9%\n",
      "epoch 28, 35.0s: 100.0%\n",
      "epoch 29, 35.8s: 99.9%\n",
      "test: 99.3%\n"
     ]
    }
   ],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_size, kernel_size=3, stride=1, padding=0):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.in_size = np.array(in_size)\n",
    "        self.out_size = (self.in_size + 2 * padding - kernel_size) // stride + 1\n",
    "        self.num_params = out_channels * (in_channels * kernel_size ** 2 + 3)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, in_size):\n",
    "        super(InceptionBlock, self).__init__()\n",
    "        self.in_channels = in_channels \n",
    "        self.out_channels = out_channels\n",
    "        self.in_size = np.array(in_size),\n",
    "        self.out_size = np.array(in_size),\n",
    "        self.num_params = sum([\n",
    "            self.out_channels // 4 * (self.in_channels * 1 ** 2 + 3),\n",
    "            sum([\n",
    "                self.out_channels // 2 * (self.in_channels * 1 ** 2 + 3),\n",
    "                self.out_channels // 2 * (self.out_channels // 2 * 3 ** 2 + 3)\n",
    "            ]),\n",
    "            sum([\n",
    "                self.out_channels // 16 * (self.in_channels * 1 ** 2 + 3),\n",
    "                self.out_channels // 8 * (self.out_channels // 16 * 5 ** 2 + 3)\n",
    "            ]),\n",
    "            self.out_channels // 8 * (self.in_channels * 1 ** 2 + 3)\n",
    "        ])\n",
    "        \n",
    "        self.branch1 = ConvBlock(in_channels, out_channels // 4, self.in_size, kernel_size=1) \n",
    "        self.branch2 = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels // 2, self.in_size, kernel_size=1), \n",
    "            ConvBlock(out_channels // 2, out_channels // 2, self.in_size, kernel_size=3, padding=1) \n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels // 16, self.in_size, kernel_size=1), \n",
    "            ConvBlock(out_channels // 16, out_channels // 8, self.in_size, kernel_size=5, padding=2), \n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            ConvBlock(in_channels, out_channels // 8, self.in_size, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, in_size):\n",
    "        super(Inception, self).__init__()\n",
    "        self.in_size = np.array(in_size)\n",
    "        self.cnv_1 = ConvBlock(in_channels, 64, self.in_size, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inc_1 = InceptionBlock(64, 32, self.in_size // 2)\n",
    "        self.inc_2 = InceptionBlock(32, 32, self.in_size // 2)\n",
    "        self.inc_3 = InceptionBlock(32, 64, self.in_size // 2)\n",
    "        self.inc_4 = InceptionBlock(64, 64, self.in_size // 2) # \n",
    "        self.avgp = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.dout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnv_1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.inc_1(x)\n",
    "        x = self.inc_2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.inc_3(x)\n",
    "        x = self.inc_4(x)\n",
    "        x = self.avgp(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model =  Inception(1, 10, (28, 28))\n",
    "# summary(model, (1, 28, 28))\n",
    "train('TinyInception', model, train_loader)\n",
    "print(f'test: {accuracy(model, test_loader):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 26])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.out_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
